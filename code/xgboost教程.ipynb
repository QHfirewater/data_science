{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from  sklearn.model_selection import train_test_split,GridSearchCV,KFold\n",
    "from sklearn.metrics import confusion_matrix,mean_squared_error\n",
    "from sklearn.datasets import load_iris,load_digits,load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(31337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二分类混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= digits['data']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = digits['target']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=2,shuffle=True,random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:13:29] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[[84  0  0  0  0  2  0  0  0  0]\n",
      " [ 2 86  0  0  0  0  0  0  0  2]\n",
      " [ 1  1 75  3  0  0  1  0  1  1]\n",
      " [ 0  0  1 90  0  2  0  1  2  2]\n",
      " [ 0  0  0  0 84  0  0  0  1  1]\n",
      " [ 0  0  0  0  2 94  0  0  1  2]\n",
      " [ 0  0  2  0  1  0 86  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 93  0  1]\n",
      " [ 0  1  1  0  0  1  0  0 76  2]\n",
      " [ 1  0  0  0  0  2  0  0  4 86]]\n",
      "[18:13:30] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87  0  0  0  2  0  0  0  3  0]\n",
      " [ 0 90  0  1  0  0  0  0  0  1]\n",
      " [ 1  1 91  0  0  0  0  0  1  0]\n",
      " [ 0  1  1 80  0  1  0  1  1  0]\n",
      " [ 3  1  0  0 88  0  0  1  1  1]\n",
      " [ 0  0  0  0  0 81  0  0  0  2]\n",
      " [ 0  0  0  0  0  0 90  0  2  0]\n",
      " [ 0  0  0  0  1  0  0 83  1  0]\n",
      " [ 0  6  0  2  0  1  2  2 78  2]\n",
      " [ 0  0  0  1  0  0  0  2  0 84]]\n"
     ]
    }
   ],
   "source": [
    "for train_index,test_index in kf.split(x):\n",
    "    xgb_model = xgb.XGBClassifier().fit(x[train_index],y[train_index])\n",
    "    pred = xgb_model.predict(x[test_index])\n",
    "    actual = y[test_index]\n",
    "    print(confusion_matrix(actual,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:16:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[[29  0  0]\n",
      " [ 0 24  1]\n",
      " [ 0  1 20]]\n",
      "[18:16:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[[21  0  0]\n",
      " [ 0 21  4]\n",
      " [ 0  2 27]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "D:\\software\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "y = iris['target']\n",
    "x = iris['data']\n",
    "kf = KFold(2,shuffle=True,random_state=rng)\n",
    "for train_index,test_index in kf.split(x):\n",
    "    xgb_model = xgb.XGBClassifier().fit(x[train_index],y[train_index])\n",
    "    pred = xgb_model.predict(x[test_index])\n",
    "    actual = y[test_index]\n",
    "    print(confusion_matrix(actual,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.262105023328399\n",
      "10.144190394517386\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "y = boston['target']\n",
    "x = boston['data']\n",
    "kf = KFold(2,shuffle=True,random_state=rng)\n",
    "for train_index,test_index in kf.split(x):\n",
    "    xgb_model = xgb.XGBRegressor().fit(x[train_index],y[train_index])\n",
    "    pred = xgb_model.predict(x[test_index])\n",
    "    actual = y[test_index]\n",
    "    print(mean_squared_error(actual,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = boston['target']\n",
    "x  = boston['data']\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "para_dict = {'max_depth':[2,4,6],\n",
    "             'n_estimators':[50,100,200]}\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    enable_categorical=False, gamma=None,\n",
       "                                    gpu_id=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None, predictor=None,\n",
       "                                    random_state=None, reg_alpha=None,\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             param_grid={'max_depth': [2, 4, 6],\n",
       "                         'n_estimators': [50, 100, 200]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(xgb_model,para_dict,verbose=1)\n",
    "clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2, 'n_estimators': 100}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mType:\u001b[0m        module\n",
      "\u001b[1;31mString form:\u001b[0m <module 'xgboost' from 'D:\\\\software\\\\anaconda\\\\lib\\\\site-packages\\\\xgboost\\\\__init__.py'>\n",
      "\u001b[1;31mFile:\u001b[0m        d:\\software\\anaconda\\lib\\site-packages\\xgboost\\__init__.py\n",
      "\u001b[1;31mDocstring:\u001b[0m  \n",
      "XGBoost: eXtreme Gradient Boosting library.\n",
      "\n",
      "Contributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mobjective\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'reg:squarederror'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Implementation of the scikit-learn API for XGBoost regression.\n",
      "\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "\n",
      "    n_estimators : int\n",
      "        Number of gradient boosted trees.  Equivalent to number of boosting\n",
      "        rounds.\n",
      "\n",
      "    max_depth :  Optional[int]\n",
      "        Maximum tree depth for base learners.\n",
      "    learning_rate : Optional[float]\n",
      "        Boosting learning rate (xgb's \"eta\")\n",
      "    verbosity : Optional[int]\n",
      "        The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
      "    objective : typing.Union[str, typing.Callable[[numpy.ndarray, numpy.ndarray], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\n",
      "        Specify the learning task and the corresponding learning objective or\n",
      "        a custom objective function to be used (see note below).\n",
      "    booster: Optional[str]\n",
      "        Specify which booster to use: gbtree, gblinear or dart.\n",
      "    tree_method: Optional[str]\n",
      "        Specify which tree method to use.  Default to auto.  If this parameter\n",
      "        is set to default, XGBoost will choose the most conservative option\n",
      "        available.  It's recommended to study this option from the parameters\n",
      "        document: https://xgboost.readthedocs.io/en/latest/treemethod.html.\n",
      "    n_jobs : Optional[int]\n",
      "        Number of parallel threads used to run xgboost.  When used with other Scikit-Learn\n",
      "        algorithms like grid search, you may choose which algorithm to parallelize and\n",
      "        balance the threads.  Creating thread contention will significantly slow down both\n",
      "        algorithms.\n",
      "    gamma : Optional[float]\n",
      "        Minimum loss reduction required to make a further partition on a leaf\n",
      "        node of the tree.\n",
      "    min_child_weight : Optional[float]\n",
      "        Minimum sum of instance weight(hessian) needed in a child.\n",
      "    max_delta_step : Optional[float]\n",
      "        Maximum delta step we allow each tree's weight estimation to be.\n",
      "    subsample : Optional[float]\n",
      "        Subsample ratio of the training instance.\n",
      "    colsample_bytree : Optional[float]\n",
      "        Subsample ratio of columns when constructing each tree.\n",
      "    colsample_bylevel : Optional[float]\n",
      "        Subsample ratio of columns for each level.\n",
      "    colsample_bynode : Optional[float]\n",
      "        Subsample ratio of columns for each split.\n",
      "    reg_alpha : Optional[float]\n",
      "        L1 regularization term on weights (xgb's alpha).\n",
      "    reg_lambda : Optional[float]\n",
      "        L2 regularization term on weights (xgb's lambda).\n",
      "    scale_pos_weight : Optional[float]\n",
      "        Balancing of positive and negative weights.\n",
      "    base_score : Optional[float]\n",
      "        The initial prediction score of all instances, global bias.\n",
      "    random_state : Optional[Union[numpy.random.RandomState, int]]\n",
      "        Random number seed.\n",
      "\n",
      "        .. note::\n",
      "\n",
      "           Using gblinear booster with shotgun updater is nondeterministic as\n",
      "           it uses Hogwild algorithm.\n",
      "\n",
      "    missing : float, default np.nan\n",
      "        Value in the data which needs to be present as a missing value.\n",
      "    num_parallel_tree: Optional[int]\n",
      "        Used for boosting random forest.\n",
      "    monotone_constraints : Optional[Union[Dict[str, int], str]]\n",
      "        Constraint of variable monotonicity.  See tutorial for more\n",
      "        information.\n",
      "    interaction_constraints : Optional[Union[str, List[Tuple[str]]]]\n",
      "        Constraints for interaction representing permitted interactions.  The\n",
      "        constraints must be specified in the form of a nest list, e.g. [[0, 1],\n",
      "        [2, 3, 4]], where each inner list is a group of indices of features\n",
      "        that are allowed to interact with each other.  See tutorial for more\n",
      "        information\n",
      "    importance_type: Optional[str]\n",
      "        The feature importance type for the feature_importances\\_ property:\n",
      "\n",
      "        * For tree model, it's either \"gain\", \"weight\", \"cover\", \"total_gain\" or\n",
      "          \"total_cover\".\n",
      "        * For linear model, only \"weight\" is defined and it's the normalized coefficients\n",
      "          without bias.\n",
      "\n",
      "    gpu_id : Optional[int]\n",
      "        Device ordinal.\n",
      "    validate_parameters : Optional[bool]\n",
      "        Give warnings for unknown parameter.\n",
      "    predictor : Optional[str]\n",
      "        Force XGBoost to use specific predictor, available choices are [cpu_predictor,\n",
      "        gpu_predictor].\n",
      "    enable_categorical : bool\n",
      "\n",
      "        .. versionadded:: 1.5.0\n",
      "\n",
      "        Experimental support for categorical data.  Do not set to true unless you are\n",
      "        interested in development. Only valid when `gpu_hist` and dataframe are used.\n",
      "\n",
      "    kwargs : dict, optional\n",
      "        Keyword arguments for XGBoost Booster object.  Full documentation of\n",
      "        parameters can be found here:\n",
      "        https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst.\n",
      "        Attempting to set a parameter via the constructor args and \\*\\*kwargs\n",
      "        dict simultaneously will result in a TypeError.\n",
      "\n",
      "        .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      "\n",
      "            \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee\n",
      "            that parameters passed via this argument will interact properly\n",
      "            with scikit-learn.\n",
      "\n",
      "        .. note::  Custom objective function\n",
      "\n",
      "            A custom objective function can be provided for the ``objective``\n",
      "            parameter. In this case, it should have the signature\n",
      "            ``objective(y_true, y_pred) -> grad, hess``:\n",
      "\n",
      "            y_true: array_like of shape [n_samples]\n",
      "                The target values\n",
      "            y_pred: array_like of shape [n_samples]\n",
      "                The predicted values\n",
      "\n",
      "            grad: array_like of shape [n_samples]\n",
      "                The value of the gradient for each sample point.\n",
      "            hess: array_like of shape [n_samples]\n",
      "                The value of the second derivative for each sample point\n",
      "\u001b[1;31mFile:\u001b[0m           d:\\software\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     XGBRFRegressor\n"
     ]
    }
   ],
   "source": [
    "xgb.XGBRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.98544\n",
      "[1]\tvalidation_0-auc:0.99122\n",
      "[2]\tvalidation_0-auc:0.99268\n",
      "[3]\tvalidation_0-auc:0.99368\n",
      "[4]\tvalidation_0-auc:0.99414\n",
      "[5]\tvalidation_0-auc:0.99495\n",
      "[6]\tvalidation_0-auc:0.99569\n",
      "[7]\tvalidation_0-auc:0.99611\n",
      "[8]\tvalidation_0-auc:0.99650\n",
      "[9]\tvalidation_0-auc:0.99684\n",
      "[10]\tvalidation_0-auc:0.99716\n",
      "[11]\tvalidation_0-auc:0.99746\n",
      "[12]\tvalidation_0-auc:0.99752\n",
      "[13]\tvalidation_0-auc:0.99768\n",
      "[14]\tvalidation_0-auc:0.99794\n",
      "[15]\tvalidation_0-auc:0.99808\n",
      "[16]\tvalidation_0-auc:0.99815\n",
      "[17]\tvalidation_0-auc:0.99828\n",
      "[18]\tvalidation_0-auc:0.99835\n",
      "[19]\tvalidation_0-auc:0.99845\n",
      "[20]\tvalidation_0-auc:0.99854\n",
      "[21]\tvalidation_0-auc:0.99855\n",
      "[22]\tvalidation_0-auc:0.99868\n",
      "[23]\tvalidation_0-auc:0.99869\n",
      "[24]\tvalidation_0-auc:0.99877\n",
      "[25]\tvalidation_0-auc:0.99877\n",
      "[26]\tvalidation_0-auc:0.99881\n",
      "[27]\tvalidation_0-auc:0.99886\n",
      "[28]\tvalidation_0-auc:0.99885\n",
      "[29]\tvalidation_0-auc:0.99891\n",
      "[30]\tvalidation_0-auc:0.99891\n",
      "[31]\tvalidation_0-auc:0.99891\n",
      "[32]\tvalidation_0-auc:0.99891\n",
      "[33]\tvalidation_0-auc:0.99891\n",
      "[34]\tvalidation_0-auc:0.99892\n",
      "[35]\tvalidation_0-auc:0.99892\n",
      "[36]\tvalidation_0-auc:0.99897\n",
      "[37]\tvalidation_0-auc:0.99897\n",
      "[38]\tvalidation_0-auc:0.99897\n",
      "[39]\tvalidation_0-auc:0.99899\n",
      "[40]\tvalidation_0-auc:0.99901\n",
      "[41]\tvalidation_0-auc:0.99903\n",
      "[42]\tvalidation_0-auc:0.99901\n",
      "[43]\tvalidation_0-auc:0.99902\n",
      "[44]\tvalidation_0-auc:0.99902\n",
      "[45]\tvalidation_0-auc:0.99903\n",
      "[46]\tvalidation_0-auc:0.99902\n",
      "[47]\tvalidation_0-auc:0.99904\n",
      "[48]\tvalidation_0-auc:0.99904\n",
      "[49]\tvalidation_0-auc:0.99902\n",
      "[50]\tvalidation_0-auc:0.99904\n",
      "[51]\tvalidation_0-auc:0.99903\n",
      "[52]\tvalidation_0-auc:0.99905\n",
      "[53]\tvalidation_0-auc:0.99904\n",
      "[54]\tvalidation_0-auc:0.99906\n",
      "[55]\tvalidation_0-auc:0.99904\n",
      "[56]\tvalidation_0-auc:0.99906\n",
      "[57]\tvalidation_0-auc:0.99905\n",
      "[58]\tvalidation_0-auc:0.99904\n",
      "[59]\tvalidation_0-auc:0.99904\n",
      "[60]\tvalidation_0-auc:0.99905\n",
      "[61]\tvalidation_0-auc:0.99904\n",
      "[62]\tvalidation_0-auc:0.99903\n",
      "[63]\tvalidation_0-auc:0.99905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = digits['data']\n",
    "y = digits['target']\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=0)\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False)\n",
    "clf.fit(x_train,y_train,early_stopping_rounds=10,eval_metric='auc',eval_set=[(x_test,y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iris = load_iris()\n",
    "y = iris['target']\n",
    "x  = iris['data']\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:15:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = ['sepal_length','sepal_with','petal_lenth','pental_width']\n",
    "feature_importance = xgb_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00959796, 0.01645038, 0.6765859 , 0.29736578], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice = np.argsort(feature_importance)[::-1]\n",
    "indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征petal_lenth 的重要程度为 0.676586 \n",
      "特征pental_width 的重要程度为 0.297366 \n",
      "特征sepal_with 的重要程度为 0.016450 \n",
      "特征sepal_length 的重要程度为 0.009598 \n"
     ]
    }
   ],
   "source": [
    "for index in indice:\n",
    "    print('特征%s 的重要程度为 %f ' % (feature_name[index],feature_importance[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1b9e66dc580>,\n",
       "  <matplotlib.axis.XTick at 0x1b9e66dc550>,\n",
       "  <matplotlib.axis.XTick at 0x1b9e66da1f0>,\n",
       "  <matplotlib.axis.XTick at 0x1b9e6082760>],\n",
       " [Text(0, 0, 'petal_lenth'),\n",
       "  Text(1, 0, 'pental_width'),\n",
       "  Text(2, 0, 'sepal_with'),\n",
       "  Text(3, 0, 'sepal_length')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6IAAAHjCAYAAAA5Y6JnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgaElEQVR4nO3de5RlZ13n4e+PDlHCLWha0VxIxAATHEApAihgHEUD6oqMLElAMd6yokZGHZQoDhdZqBmdQYVgpsWIikNEUYyABGY03DN2BcMlSJgmA6SJQCcg4SYx8Js/zm44FNVdpzvVb3VVnmetXqmz99tnv92r3pzzqb3P7uruAAAAwCi32+gJAAAAcNsiRAEAABhKiAIAADCUEAUAAGAoIQoAAMBQQhQAAIChhCgAG66q7l1V/1hVH6+qJ230fA5EVT2hql690fMAgM2k/DuiAGy0qvqDJDd198+tw3NdnuRF3f2CWz2xTaaqzk7y4939sI2eCwDsjzOiABwO7pHk6o2eRJJU1REbPYeDsVnnDcBtkxAFYENV1d8l+bYkz6uqT1TVvarqy6rqt6rq/VX1oaq6qKruMI2/W1W9vKr2VNVHp6+Pm/Y9O8nD557reVV1YlX1fKhV1eVV9ePT12dX1Rur6jlV9ZEkz9jf8VeZ/9lV9Ya5x11VP1VV/3e61PhZVXXPqnpzVd1UVS+pqiOnsadV1e6q+uWquqGq3ltVT5h7rrtW1R9Pf9b3VdWvVNXt9jHvP0tyUZKHTn/2f5nGffd02fNNVXVdVT1j7vn3/t388PRnvaGqnjq3f9s0t/dMf5Yrq+r4ad99quo1VfWRqrqmqn7g4L8LALitEaIAbKju/g9JXp/kvO6+U3e/O8kFSe6V5AFJvj7JsUmeNv2W2yX5w8zOop6Q5NNJnjc911NXPNd5C07jwUmuTfJVSZ69xvEXcXqSByZ5SJJfTLIjyROSHJ/kG5KcNTf27kmOmY7xw0l2VNW9p33PTXLXJF+X5FuTPDHJj+xj3j+Y5Nwkb57+7EdPYz45/b6jk3x3kp+squ9bMd+HJbl3km9P8rSq+nfT9p+f5vroJHdJ8qNJPlVVd0zymiT/czr2WUmeX1X3XfyvCIDbMiEKwGGlqirJTyT5ue7+SHd/PMmvJTkzSbr7xu5+aXd/atr37Mwi7da4vruf2923JPnX/R1/QRd0903dfXWSdyR5dXdf290fS/K3Sb5xxfj/0t2f6e7XJnlFkh+oqm1JHpfkl7r749393iT/LckPrTbv7v70ahPp7su7++3d/bnufluSF+dL/76e2d2f7u63JnlrkvtP2388ya909zU989buvjHJ9yR5b3f/4XTstyR5aZLHHsDfEQC3YT5PAsDhZnuSo5JcOWvSJEkl2ZYkVXVUkudkdtbxbtP+O1fVtu7+7EEe87pFj7+gD819/elVHt997vFHu/uTc4/fl+RrMztLeuT0eH7fsfuY96qq6sFJfiOzM7FHJvmyJH++YtgH577+VJI7TV8fn+Q9qzztPZI8eO/lv5MjkvzJWvMBgMQZUQAOPzdkFmv37e6jp1937e69cfSfM7uM9MHdfZckj5i2763GlbeD3xt5R81tu/uKMfO/Z63jr7e7TZe67nVCkuunefxbZtE3v+8D+5j3ao+T2eWzlyY5vrvvmtnnSGuVcau5Lsk997H9tXN/P0dPlwP/5ILPC8BtnBAF4LDS3Z9L8vtJnlNVX5UkVXVsVX3XNOTOmYXiv1TVVyR5+oqn+FBmn6nc+3x7Mou3H5xuvvOjWT2uFj3+ofDMqjqyqh6e2WWvfz6d3X1JkmdX1Z2r6h6ZfWbzRft5ng8lOW7vzZAmd07yke7+16o6NcnjD2BeL0jyrKo6uWbuV1VfmeTlSe5VVT9UVbeffj1o7rOlALBfQhSAw9FTkuxKckVV3ZTkf2V2FjRJfjvJHTI7Y3hFklet+L2/k+Sx0x11f3fa9hNJfiHJjUnum+RNt+L46+2DST6a2VnQP01ybne/a9r3M5md0b02yRsyO7t58X6e6+8y+2dwPlhVN0zbfirJr1bVxzO74dJLDmBu/30a/+okNyX5gyR3mD43+52ZfW72+unPcEFml/0CwJqqe7WreACAQ62qTkvyou4+boOnAgBDOSMKAADAUEIUAACAoVyaCwAAwFDOiAIAADCUEAUAAGCoIzbqwMccc0yfeOKJG3V4AAAADqErr7zyhu7evtq+DQvRE088McvLyxt1eAAAAA6hqnrfvva5NBcAAIChFgrRqjq9qq6pql1Vdf4q+3+hqq6afr2jqj5bVV+x/tMFAABgs1szRKtqW5ILkzwqySlJzqqqU+bHdPdvdvcDuvsBSX4pyWu7+yOHYL4AAABscoucET01ya7uvra7b05ySZIz9jP+rCQvXo/JAQAAsPUsEqLHJrlu7vHuaduXqKqjkpye5KX72H9OVS1X1fKePXsOdK4AAABsAYuEaK2yrfcx9nuTvHFfl+V2947uXurupe3bV72LLwAAAFvcIiG6O8nxc4+PS3L9PsaeGZflAgAAsB+LhOjOJCdX1UlVdWRmsXnpykFVddck35rkr9d3igAAAGwlR6w1oLtvqarzklyWZFuSi7v76qo6d9p/0TT0MUle3d2fPGSzBQAAYNOr7n193PPQWlpa6uXl5Q05NgAAAIdWVV3Z3Uur7Vvk0lwAAABYN0IUAACAoYQoAAAAQwlRAAAAhhKiAAAADCVEAQAAGEqIAgAAMJQQBQAAYCghCgAAwFBHbPQEDmdVGz0DWEz3Rs8AAAAW54woAAAAQwlRAAAAhhKiAAAADCVEAQAAGEqIAgAAMJQQBQAAYCghCgAAwFBCFAAAgKGEKAAAAEMJUQAAAIYSogAAAAwlRAEAABhKiAIAADCUEAUAAGAoIQoAAMBQQhQAAIChhCgAAABDCVEAAACGEqIAAAAMJUQBAAAYSogCAAAwlBAFAABgKCEKAADAUEIUAACAoYQoAAAAQwlRAAAAhhKiAAAADCVEAQAAGEqIAgAAMJQQBQAAYCghCgAAwFBCFAAAgKGEKAAAAEMJUQAAAIYSogAAAAwlRAEAABhKiAIAADCUEAUAAGAoIQoAAMBQQhQAAIChhCgAAABDCVEAAACGWihEq+r0qrqmqnZV1fn7GHNaVV1VVVdX1WvXd5oAAABsFUesNaCqtiW5MMkjk+xOsrOqLu3ud86NOTrJ85Oc3t3vr6qvOkTzBQAAYJNb5IzoqUl2dfe13X1zkkuSnLFizOOT/GV3vz9JuvvD6ztNAAAAtopFQvTYJNfNPd49bZt3ryR3q6rLq+rKqnriek0QAACArWXNS3OT1CrbepXneWCSb09yhyRvrqoruvvdX/REVeckOSdJTjjhhAOfLQAAAJveImdEdyc5fu7xcUmuX2XMq7r7k919Q5LXJbn/yifq7h3dvdTdS9u3bz/YOQMAALCJLRKiO5OcXFUnVdWRSc5McumKMX+d5OFVdURVHZXkwUn+aX2nCgAAwFaw5qW53X1LVZ2X5LIk25Jc3N1XV9W50/6LuvufqupVSd6W5HNJXtDd7ziUEwcAAGBzqu6VH/ccY2lpqZeXlzfk2Iuq1T4dC4ehDVrGAACwT1V1ZXcvrbZvkUtzAQAAYN0IUQAAAIYSogAAAAwlRAEAABhKiAIAADCUEAUAAGAoIQoAAMBQQhQAAIChhCgAAABDCVEAAACGEqIAAAAMJUQBAAAYSogCAAAwlBAFAABgKCEKAADAUEIUAACAoYQoAAAAQwlRAAAAhhKiAAAADCVEAQAAGEqIAgAAMJQQBQAAYCghCgAAwFBCFAAAgKGEKAAAAEMJUQAAAIYSogAAAAwlRAEAABhKiAIAADCUEAUAAGAoIQoAAMBQQhQAAIChhCgAAABDCVEAAACGEqIAAAAMJUQBAAAYSogCAAAwlBAFAABgKCEKAADAUEIUAACAoYQoAAAAQwlRAAAAhhKiAAAADCVEAQAAGEqIAgAAMJQQBQAAYCghCgAAwFBCFAAAgKGEKAAAAEMJUQAAAIYSogAAAAwlRAEAABhqoRCtqtOr6pqq2lVV56+y/7Sq+lhVXTX9etr6TxUAAICt4Ii1BlTVtiQXJnlkkt1JdlbVpd39zhVDX9/d33MI5ggAAMAWssgZ0VOT7Orua7v75iSXJDnj0E4LAACArWqRED02yXVzj3dP21Z6aFW9tar+tqruuy6zAwAAYMtZ89LcJLXKtl7x+C1J7tHdn6iqRyd5WZKTv+SJqs5Jck6SnHDCCQc2UwAAALaERc6I7k5y/Nzj45JcPz+gu2/q7k9MX78yye2r6piVT9TdO7p7qbuXtm/ffiumDQAAwGa1SIjuTHJyVZ1UVUcmOTPJpfMDquruVVXT16dOz3vjek8WAACAzW/NS3O7+5aqOi/JZUm2Jbm4u6+uqnOn/RcleWySn6yqW5J8OsmZ3b3y8l0AAABIbVQvLi0t9fLy8oYce1G12qdj4TDkxz4AABxuqurK7l5abd8il+YCAADAuhGiAAAADCVEAQAAGEqIAgAAMJQQBQAAYCghCgAAwFBCFAAAgKGEKAAAAEMJUQAAAIYSogAAAAwlRAEAABhKiAIAADCUEAUAAGAoIQoAAMBQQhQAAIChhCgAAABDCVEAAACGEqIAAAAMJUQBAAAYSogCAAAwlBAFAABgKCEKAADAUEIUAACAoYQoAAAAQwlRAAAAhhKiAAAADCVEAQAAGEqIAgAAMJQQBQAAYCghCgAAwFBCFAAAgKGEKAAAAEMJUQAAAIYSogAAAAwlRAEAABhKiAIAADCUEAUAAGAoIQoAAMBQQhQAAIChhCgAAABDCVEAAACGEqIAAAAMJUQBAAAYSogCAAAwlBAFAABgKCEKAADAUEIUAACAoYQoAAAAQwlRAAAAhhKiAAAADCVEAQAAGEqIAgAAMNRCIVpVp1fVNVW1q6rO38+4B1XVZ6vqses3RQAAALaSNUO0qrYluTDJo5KckuSsqjplH+MuSHLZek8SAACArWORM6KnJtnV3dd2981JLklyxirjfibJS5N8eB3nBwAAwBazSIgem+S6uce7p22fV1XHJnlMkovWb2oAAABsRYuEaK2yrVc8/u0kT+nuz+73iarOqarlqlres2fPglMEAABgKzligTG7kxw/9/i4JNevGLOU5JKqSpJjkjy6qm7p7pfND+ruHUl2JMnS0tLKmAUAAOA2YJEQ3Znk5Ko6KckHkpyZ5PHzA7r7pL1fV9ULk7x8ZYQCAABAskCIdvctVXVeZnfD3Zbk4u6+uqrOnfb7XCgAAAALW+SMaLr7lUleuWLbqgHa3Wff+mkBAACwVS1ysyIAAABYN0IUAACAoYQoAAAAQwlRAAAAhhKiAAAADCVEAQAAGEqIAgAAMJQQBQAAYCghCgAAwFBCFAAAgKGEKAAAAEMJUQAAAIYSogAAAAwlRAEAABhKiAIAADCUEAUAAGAoIQoAAMBQQhQAAIChhCgAAABDCVEAAACGEqIAAAAMJUQBAAAYSogCAAAwlBAFAABgKCEKAADAUEIUAACAoYQoAAAAQwlRAAAAhhKiAAAADCVEAQAAGEqIAgAAMJQQBQAAYCghCgAAwFBCFAAAgKGEKAAAAEMJUQAAAIYSogAAAAwlRAEAABhKiAIAADCUEAUAAGAoIQoAAMBQQhQAAIChhCgAAABDCVEAAACGEqIAAAAMJUQBAAAYSogCAAAwlBAFAABgKCEKAADAUEIUAACAoYQoAAAAQwlRAAAAhlooRKvq9Kq6pqp2VdX5q+w/o6reVlVXVdVyVT1s/acKAADAVnDEWgOqaluSC5M8MsnuJDur6tLufufcsP+d5NLu7qq6X5KXJLnPoZgwAAAAm9siZ0RPTbKru6/t7puTXJLkjPkB3f2J7u7p4R2TdAAAAGAVi4TosUmum3u8e9r2RarqMVX1riSvSPKj6zM9AAAAtppFQrRW2fYlZzy7+6+6+z5Jvi/Js1Z9oqpzps+QLu/Zs+eAJgoAAMDWsEiI7k5y/Nzj45Jcv6/B3f26JPesqmNW2beju5e6e2n79u0HPFkAAAA2vzVvVpRkZ5KTq+qkJB9IcmaSx88PqKqvT/Ke6WZF35TkyCQ3rvdkgc2tVru+Ag5D7U4HAHBIrRmi3X1LVZ2X5LIk25Jc3N1XV9W50/6Lknx/kidW1b8l+XSSx83dvAgAAAA+rzaqF5eWlnp5eXlDjr0oZ2/YLDbLj32sKTaLzbKmAOBwVlVXdvfSavsW+YwoAAAArBshCgAAwFBCFAAAgKGEKAAAAEMJUQAAAIYSogAAAAwlRAEAABhKiAIAADCUEAUAAGAoIQoAAMBQQhQAAIChhCgAAABDCVEAAACGEqIAAAAMJUQBAAAYSogCAAAwlBAFAABgKCEKAADAUEIUAACAoYQoAAAAQwlRAAAAhhKiAAAADCVEAQAAGEqIAgAAMJQQBQAAYCghCgAAwFBCFAAAgKGEKAAAAEMJUQAAAIYSogAAAAwlRAEAABhKiAIAADCUEAUAAGAoIQoAAMBQQhQAAIChhCgAAABDCVEAAACGEqIAAAAMJUQBAAAYSogCAAAwlBAFAABgKCEKAADAUEIUAACAoYQoAAAAQwlRAAAAhhKiAAAADCVEAQAAGEqIAgAAMJQQBQAAYCghCgAAwFBCFAAAgKGEKAAAAEMJUQAAAIZaKESr6vSquqaqdlXV+avsf0JVvW369aaquv/6TxUAAICtYM0QraptSS5M8qgkpyQ5q6pOWTHs/yX51u6+X5JnJdmx3hMFAABga1jkjOipSXZ197XdfXOSS5KcMT+gu9/U3R+dHl6R5Lj1nSYAAABbxSIhemyS6+Ye75627cuPJfnb1XZU1TlVtVxVy3v27Fl8lgAAAGwZi4RorbKtVx1Y9W2ZhehTVtvf3Tu6e6m7l7Zv3774LAEAANgyjlhgzO4kx889Pi7J9SsHVdX9krwgyaO6+8b1mR4AAABbzSJnRHcmObmqTqqqI5OcmeTS+QFVdUKSv0zyQ9397vWfJgAAAFvFmmdEu/uWqjovyWVJtiW5uLuvrqpzp/0XJXlakq9M8vyqSpJbunvp0E0bAACAzaq6V/245yG3tLTUy8vLG3LsRdVqn46Fw9AGLeMDZk2xWWyWNQUAh7OqunJfJygXuTQXAAAA1o0QBQAAYCghCgAAwFBCFAAAgKGEKAAAAEMJUQAAAIYSogAAAAwlRAEAABhKiAIAADCUEAUAAGAoIQoAAMBQQhQAAIChhCgAAABDCVEAAACGEqIAAAAMJUQBAAAYSogCAAAwlBAFAABgKCEKAADAUEIUAACAoYQoAAAAQwlRAAAAhhKiAAAADCVEAQAAGEqIAgAAMJQQBQAAYCghCgAAwFBCFAAAgKGEKAAAAEMJUQAAAIYSogAAAAwlRAEAABhKiAIAADCUEAUAAGAoIQoAAMBQQhQAAIChhCgAAABDCVEAAACGEqIAAAAMJUQBAAAYSogCAAAwlBAFAABgKCEKAADAUEIUAACAoYQoAAAAQwlRAAAAhhKiAAAADCVEAQAAGEqIAgAAMJQQBQAAYCghCgAAwFBCFAAAgKEWCtGqOr2qrqmqXVV1/ir771NVb66qz1TVk9d/mgAAAGwVR6w1oKq2JbkwySOT7E6ys6ou7e53zg37SJInJfm+QzFJAAAAto5FzoiemmRXd1/b3TcnuSTJGfMDuvvD3b0zyb8dgjkCAACwhSwSoscmuW7u8e5pGwAAABywRUK0VtnWB3OwqjqnqparannPnj0H8xQAAABscouE6O4kx889Pi7J9QdzsO7e0d1L3b20ffv2g3kKAAAANrlFQnRnkpOr6qSqOjLJmUkuPbTTAgAAYKta86653X1LVZ2X5LIk25Jc3N1XV9W50/6LquruSZaT3CXJ56rqZ5Oc0t03HbqpAwAAsBmtGaJJ0t2vTPLKFdsumvv6g5ldsgsAAAD7tciluQAAALBuhCgAAABDCVEAAACGEqIAAAAMJUQBAAAYSogCAAAwlBAFAABgKCEKAADAUEIUAACAoYQoAAAAQwlRAAAAhhKiAAAADCVEAQAAGEqIAgAAMJQQBQAAYCghCgAAwFBCFAAAgKGEKAAAAEMJUQAAAIYSogAAAAwlRAEAABhKiAIAADCUEAUAAGAoIQoAAMBQQhQAAIChhCgAAABDCVEAAACGEqIAAAAMJUQBAAAYSogCAAAwlBAFAABgKCEKAADAUEIUAACAoYQoAAAAQwlRAAAAhhKiAAAADCVEAQAAGEqIAgAAMJQQBQAAYCghCgAAwFBCFAAAgKGEKAAAAEMJUQAAAIYSogAAAAwlRAEAABhKiAIAADDUERs9AQDg4FVt9AxgMd0bPQPgcOKMKAAAAEMJUQAAAIYSogAAAAzlM6IAADDHZ6/ZDDb7566dEQUAAGCohUK0qk6vqmuqaldVnb/K/qqq3532v62qvmn9pwoAAMBWsGaIVtW2JBcmeVSSU5KcVVWnrBj2qCQnT7/OSfJ76zxPAAAAtohFzoiemmRXd1/b3TcnuSTJGSvGnJHkj3vmiiRHV9XXrPNcAQAA2AIWCdFjk1w393j3tO1AxwAAAMBCd81d7b5hK+/RtMiYVNU5mV26mySfqKprFjg+W8sxSW7Y6ElsNe7ud5tnXa0za+o2z5o6BKyr2zzrap1tkjV1j33tWCREdyc5fu7xcUmuP4gx6e4dSXYscEy2qKpa7u6ljZ4HbCXWFawvawrWn3XFSotcmrszyclVdVJVHZnkzCSXrhhzaZInTnfPfUiSj3X3P6/zXAEAANgC1jwj2t23VNV5SS5Lsi3Jxd19dVWdO+2/KMkrkzw6ya4kn0ryI4duygAAAGxmi1yam+5+ZWaxOb/tormvO8lPr+/U2KJcmg3rz7qC9WVNwfqzrvgiNWtIAAAAGGORz4gCAADAuhGiAAAADCVEOWBVObsqX7vAuBdW5bH72X95VQ7qNt5VOa0q37zosWCzqMoDqvLoBcadVpWX34rjLFXld/ex771VOaYqR1flp9brmHC4W8915XWK25q11s/0/vF5h+C4X/S+dO9r2Hofh/UnRDkYZydrh+ghdlryhRd42EIekKwdordWd5a786Q1hh2dfCFEgf1bsa5Oi9cpGOHsbPz7Ug6CECVVObEq76rKH1XlbVX5i6ocVZUHVuW1VbmyKpdV5Wumn+YuJfnTqlxVlTtU5WlV2VmVd1RlR1XqIObwnVV5c1XeUpU/r8qdpu3vrcozp+1vr8p9qnJiknOT/Nw0h4dPT/OIqrypKtf6qTOjHcg6msZfXpULqvIPVXl3VR5elSOT/GqSx03f24+ryqnT9/U/Tv+994Lzeft0RrOqcmNVnjht/5OqfMf8T66r8pVVefV0jP+RfH4N/0aSe05z+c1p252mP9u7qvKnB7Pe4daoyh2r8oqqvHV63XncGuvst6e1846qnDptP6TryusUh6uNXD8r5rG9Ki+d3j/urMq3TNufUZWLp2NfW/WFH5hW5b9Mrz2vqcqLq/LkWuV96TT8Z+bfO97qvzgOCSHKXvdOsqM790tyU2b/HM9zkzy2Ow9McnGSZ3fnL5IsJ3lCdx7QnU8neV53HtSdb0hyhyTfcyAHrtnlE7+S5Du6803T8//83JAbpu2/l+TJ3XlvkouSPGeaw+uncV+T5GHT8X/jwP8K4FZbaB3NjT+iO6cm+dkkT+/OzUmeluTPpu/tP0vyriSP6M43Tvt+bcG5vDHJtyS5b5Jrk8+/EX5IkitWjH16kjdMx7g0yQnT9vOTvGeayy9M275xmu8pSb5uOgaMdHqS67tz/+l151XZ/zq7Y3e+ObOz+xdP2w7puvI6xWFsI9fPvN/JbH08KMn3J3nB3L77JPmuJKcmeXpVbl+zj3J9f2avQf8xs/jMPt6XJiveOx7E/BhgoX9HlNuE67rzxunrFyX55STfkOQ1NTvfsS3JP+/j935bVX4xyVFJviLJ1Un+5gCO/ZDM3tS+cTrWkUnePLf/L6f/XpnZ/3z25WXd+VySd1blqw/g+LBeDnQdzX9vn7iP57xrkj+qyslJOsntF5zL65M8Isn7MnshPqcqxyb5SHc+UV98HvMRmdZWd15RlY/u53n/oTu7k6QqV03zfsOCc4L18PYkv1WVC5K8PMlHs/919uIk6c7rqnKXqhyd5M459OtqNV6n2GgbuX7mfUeSU+bWzF2qcufp61d05zNJPlOVDyf56sx+gPPXe0Ozas33mYu+d2QDCVH2WvkPyn48ydXdeej+flNVvjzJ85Msdee6qjwjyZcf4LEryWu6c9Y+9n9m+u9ns//v2c/Mfe1yQTbCga6jRb63n5Xk77vzmOlyv8sXnMvrMjsje0KSpyZ5TJLHJp8/M7PSov+o9Pw6W2tNwrrrzrur8sDMPkv960lek/2vs5Xf251x62olr1NsqA1eP/Nul+Shc2cwkyRTmK72OnOg62XR945sIJfmstcJVZ//n9BZmV1itH3vtumyiPtO+z+efP6nVnuj84aafa7zYD7zckWSb6nK10/HOqoq91rj98zPAQ4XB7KO9mXl9/Zdk3xg+vrsRSfSneuSHJPk5O5cm9lZyydn9TfMr0vyhGmOj0pyt33MBTZcze6O+anuvCjJbyV5cPa/zh43bX9Yko9152MZs66sHw47G7l+Vnh1kvPm5vWANca/Icn3VuXLp/eb3z23z1rbpIQoe/1Tkh+uytsyu7z2uZlF5QVVeWuSq/KFu/+9MMlF02V5n0ny+5ld6vGyJDsP9MDd2ZPZ/8hePB3/imTND5b/TZLHrLgJBGy0A1lH+/L3mV2udFVVHpfkvyb59aq8MbNLpg7E/0ny7unr1yc5NqtfRvvMzG6i8pYk35nk/UnSnRszu2T+HfWFmxXBRvv3Sf5heg16amafUdvfOvtoVd6U2Wc2f2zaNmJdeZ3icLTR62evJyVZqtnN/d6Z2c299qk7OzO7h8FbM7vsdjnJx6bdL8z0vnTuZkVsAtW96NVYbFXTZRUvnz60DhwE6wgOP1W5PLOb3C1v9Fxgsznc1k9V7jR9FvuozK7kOac7b9noeXHwXDMNAAAc7nZU5ZTMPhb2RyJ083NGlEOuKn+V5KQVm5/Sncs2Yj6wlVTlR5L8pxWb39idn96I+cBWYF3BwbN+WJQQBQAAYCg3KwIAAGAoIQoAAMBQQhQAAIChhCgAAABDCVEAAACG+v/j4WykhqXKXAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('feature importance')\n",
    "plt.bar(range(len(feature_importance)),feature_importance[indice],color = 'b')\n",
    "plt.xticks(range(len(feature_importance)),np.array(feature_name)[indice],color = 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00959796, 0.01645038, 0.6765859 , 0.29736578], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c72f12f90170356fe3abc9748a888f8a0f253bf3dee690070f84c0db82f6a8c0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
